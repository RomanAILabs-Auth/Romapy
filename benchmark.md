ğŸ¬ Loading Dolphin 2.9 (Turbo Mode)...
llama_context: n_ctx_per_seq (2048) < n_ctx_train (8192) -- the full capacity of the model will not be utilized

========================================
ğŸš€ ROMAPY TURBO CHAT (Dolphin 2.9)
Type 'exit' to quit. Use long prompts for speed tests!
========================================

You: Hey
AI: ğŸš€ [Latency: 12.42s] Hello there! How can I assist you today as Dolphin?

ğŸ“ˆ [Stats: 13 tokens | 3.41 tokens/sec]

You: I was wondering if you can write me 2 paragraphs on a topic
AI: ğŸš€ [Latency: 2.07s] Dolphin, as a language AI, can assist in generating text based on the given topic. Please provide the topic you'd like me to write about.

ğŸ“ˆ [Stats: 33 tokens | 2.54 tokens/sec]

You: write it on cheese please
AI: ğŸš€ [Latency: 1.48s] I'm not capable of physically writing on cheese as I am a text-based AI. However, I can generate the phrase you want written on cheese in text form: "write it on cheese please"

ğŸ“ˆ [Stats: 41 tokens | 3.05 tokens/sec]

You: Test
AI: ğŸš€ [Latency: 0.89s] Hello there! As Dolphin, I'm here to help you with your questions and tasks. Feel free to ask me anything you need assistance with.

ğŸ“ˆ [Stats: 30 tokens | 3.04 tokens/sec]

speed_test.py' 
Testing 10 Million operations...
âœ… RomaPy Execution Time: 0.8897 seconds
